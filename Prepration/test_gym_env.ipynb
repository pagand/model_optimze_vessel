{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yim/opt/anaconda3/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from transformers import InformerForPrediction, InformerConfig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_update(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=1, output_size=4, num_layers=1, prediction_horizon=5, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.h = prediction_horizon\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.mlp = nn.Sequential( nn.ReLU(),\n",
    "                                  nn.Linear(hidden_size, 2048),\n",
    "                                  nn.Dropout(0.2),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(2048, output_size))\n",
    "        self.hx_fc = nn.Linear(2*hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, predicted_values, past_time_features):\n",
    "        xy = torch.zeros(size=(past_time_features.shape[0], 1, self.output_size)).float().to(self.device)\n",
    "        hx = past_time_features.reshape(-1, 1, self.hidden_size)\n",
    "        hx = hx.permute(1, 0, 2)\n",
    "        out_wp = list()\n",
    "        for i in range(self.h):\n",
    "            ins = torch.cat([xy, predicted_values[:, i:i+1, :]], dim=1) # x\n",
    "            hx, _ = self.gru(ins, hx.contiguous())\n",
    "            hx = hx.reshape(-1, 2*self.hidden_size)\n",
    "            hx = self.hx_fc(hx)\n",
    "            d_xy = self.mlp(hx).reshape(-1, 1, self.output_size) #control v4\n",
    "            hx = hx.reshape(1, -1, self.hidden_size)\n",
    "            # print(\"dxy\", d_xy)\n",
    "            xy = xy + d_xy\n",
    "            # print(\"xy plused\", xy)\n",
    "            out_wp.append(xy)\n",
    "        pred_wp = torch.stack(out_wp, dim=1).squeeze(2)\n",
    "        return pred_wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yim/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "with open('../data/rl_data.pkl', 'rb') as handle:\n",
    "    rl_data = pickle.load(handle)\n",
    "with open('../data/minmax_scaler.pkl', 'rb') as handle:\n",
    "    minmax_scaler = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        # action_cols = [\"SPEED\", \"HEADING\", \"MODE\"]\n",
    "        # static_categorical_feature = [\"is_weekday\", 'direction',\"season\", \"hour\"]\n",
    "        # y_cols = [\"FC2\", \"SOG2\"] / [\"LATITUDE\", \"LONGITUDE\"]\n",
    "        # \n",
    "        # fc dynamic_real_feature = [ \"Time\", \"SPEED\", \"HEADING\", \"MODE\", \"turn\", \"acceleration\",\n",
    "        #    'current', 'rain', 'snowfall', 'wind_force', 'wind_direc', \"resist_ratio\"]\n",
    "        # loc dynamic_real_feature = [ \"Time\", \"SPEED\", \"HEADING\", \"MODE\", \"turn\", \"acceleration\",\n",
    "        #    \"distance\", 'current', 'rain', 'snowfall', 'wind_force', 'wind_direc', \"resist_ratio\", \n",
    "        #    \"change_x_factor\", \"change_y_factor\", \"FC2\", \"SOG2\"]\n",
    "\n",
    "        # obs_cols = [\"Time2\", \"turn\", \"acceleration\",\n",
    "        #    \"distance\", 'current', 'rain', 'snowfall', 'wind_force', 'wind_direc', \"resist_ratio\",\n",
    "        #    'change_x_factor', 'change_y_factor', \n",
    "        #    \"is_weekday\", 'direction', \"season\", \"hour\", \n",
    "        #    \"FC\", \"SOG\", \"LATITUDE\", 'LONGITUDE',\n",
    "        #    ],         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VesselEnvironment(gym.Env):\n",
    "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    # model = [tf_loc, gru_loc, tf_fc, gru_fc]\n",
    "    def __init__(self, rl_data, models=None, scaler=minmax_scaler):\n",
    "        self.rl_data = rl_data\n",
    "        self.trip_id = 0\n",
    "        # load best 1% trips to calculate reward1\n",
    "        self.hn_top = pd.read_csv(\"../data/H2N_top1.csv\")\n",
    "        self.nh_top = pd.read_csv(\"../data/N2H_top1.csv\")\n",
    "        # set scaler\n",
    "        self.scaler = scaler\n",
    "        # get device\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda:0')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        # load forecasting models\n",
    "        if models is None:\n",
    "            self._load_model()\n",
    "        else:\n",
    "            self.tf_loc, self.gru_loc, self.tf_fc, self.gru_fc = models\n",
    "        self._set_eval()\n",
    "\n",
    "    def _load_model(self):\n",
    "        # load transformer for longitude latitude prediction\n",
    "        config_loc = InformerConfig.from_pretrained(\"huggingface/informer-tourism-monthly\", \n",
    "                prediction_length=5, context_length=24, input_size=2, num_time_features=1,\n",
    "                num_dynamic_real_features = 16, num_static_real_features = 4,\n",
    "                lags_sequence=[1], num_static_categorical_features=0, feature_size=27)\n",
    "        self.tf_loc = InformerForPrediction(config_loc).to(self.device)\n",
    "        self.tf_loc.load_state_dict(torch.load(\"../data/gruloc_3_checkpoint22.pt\",\n",
    "                map_location=torch.device(self.device)))\n",
    "\n",
    "        # load transformer for fc sog prediction\n",
    "        config_fc = InformerConfig.from_pretrained(\"huggingface/informer-tourism-monthly\", \n",
    "                prediction_length=5, context_length=24, input_size=2, num_time_features=1,\n",
    "                num_dynamic_real_features = 11, num_static_real_features = 4,\n",
    "                lags_sequence=[1], num_static_categorical_features=0, feature_size=22)\n",
    "        self.tf_fc = InformerForPrediction(config_fc).to(self.device)\n",
    "        self.tf_fc.load_state_dict(torch.load(\"../data/gru_5_checkpoint16.pt\",\n",
    "                map_location=torch.device(self.device)))\n",
    "\n",
    "        # load gru models\n",
    "        self.gru_loc = GRU_update(2, hidden_size=425, output_size=2, num_layers=1, prediction_horizon=5, device=self.device).to(self.device)\n",
    "        self.gru_fc = GRU_update(2, hidden_size=300, output_size=2, num_layers=1, prediction_horizon=5, device=self.device).to(self.device)\n",
    "        self.gru_loc.load_state_dict(torch.load(\"../data/gruloc_3_checkpoint22_gru.pt\",\n",
    "                map_location=torch.device(self.device)))\n",
    "        self.gru_fc.load_state_dict(torch.load(\"../data/gru_5_checkpoint16_gru.pt\",\n",
    "                map_location=torch.device(self.device)))\n",
    "        \n",
    "    # set to models eval mode\n",
    "    def _set_eval(self):\n",
    "        self.gru_fc.eval()\n",
    "        self.gru_loc.eval()\n",
    "        self.tf_fc.eval()\n",
    "        self.tf_loc.eval()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        return self.obs[-25:]\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        # We need the following line to seed self.np_random\n",
    "        super().reset(seed=seed)\n",
    "        if(self.trip_id < len(rl_data)-1):\n",
    "            self.trip_id = self.trip_id + 1\n",
    "        else:\n",
    "            self.trip_id = 1\n",
    "\n",
    "        self.data = self.rl_data[self.trip_id][\"observations\"]\n",
    "        self.current_step = 25\n",
    "        self.obs = self.rl_data[self.trip_id][\"observations\"][0:25]\n",
    "        self.actions = self.rl_data[self.trip_id][\"actions\"][0:25]\n",
    "\n",
    "        # get direction and other static features\n",
    "        self.direction = self.rl_data[self.trip_id][\"observations\"][0, 13]\n",
    "        self.statics = self.rl_data[self.trip_id][\"observations\"][0, 12:16]\n",
    "        if self.direction==1:\n",
    "            self.top1 = self.hn_top\n",
    "            self.goal_long, self.goal_lat = np.float64(0.9965111208024382), np.float64(0.7729570345408661)\n",
    "        else:\n",
    "            self.top1 = self.nh_top\n",
    "            self.goal_long, self.goal_lat = np.float64(0.0023259194650222526), np.float64(0)\n",
    "\n",
    "        # calculate the cumulative reward\n",
    "        self.reward_cum = 0\n",
    "\n",
    "        return self._get_observation(), {}\n",
    "\n",
    "    def _take_action(self, action):\n",
    "        # get actions\n",
    "        speed, heading, mode = action\n",
    "        heading = heading\n",
    "        mode = int(mode>0.5)\n",
    "        if self.current_step < self.rl_data[self.trip_id][\"observations\"].shape[0]:\n",
    "            future_obs = self.rl_data[self.trip_id][\"observations\"][self.current_step].copy()\n",
    "        else:\n",
    "            future_obs = self.rl_data[self.trip_id][\"observations\"][-1].copy()\n",
    "        obs = self._get_observation().copy()\n",
    "\n",
    "        actions = self.actions[-25:].copy()\n",
    "\n",
    "        # index of features only used in the fc model\n",
    "        fc_feature_index = [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "        # get model inputs\n",
    "        past_time_features = np.zeros([25, 17])\n",
    "        past_time_features[:, 0] = obs[:, 0]\n",
    "        past_time_features[:, 1:4] = actions[:] # speed, heading, mode\n",
    "        past_time_features[:, 4:15] = obs[:, 1:12]\n",
    "        past_time_features[:, -2:] = obs[:, 16:18]**2\n",
    "\n",
    "        future_time_features = past_time_features[-5:].copy()\n",
    "        future_time_features[:, 0] = future_time_features[:, 0] + 5/120\n",
    "        future_time_features[0, [1,2,3]] = speed, heading, mode\n",
    "        future_time_features[0, 4] = heading - past_time_features[-1, 2]\n",
    "        change_x = np.cos((heading+90) * np.pi / 180)\n",
    "        change_y = np.sin((heading-90) * np.pi / 180)\n",
    "        future_time_features[0, [13,14]] = change_x, change_y\n",
    "\n",
    "        past_values = obs[:, -2:].copy()\n",
    "\n",
    "        # predict fc, sog, long, lat\n",
    "        fc2, sog2 = self._predict(past_time_features[:, 15:17], past_time_features[:,fc_feature_index], \n",
    "                                  future_time_features[:, fc_feature_index], self.tf_fc, self.gru_fc)\n",
    "        lat, long = self._predict(past_values, past_time_features, future_time_features, \n",
    "                                  self.tf_loc, self.gru_loc)\n",
    "        fc, sog = min(1, max(0, fc2)**0.5), min(1, max(0, sog2)**0.5)\n",
    "\n",
    "        # generate next observation and update obs list\n",
    "        new_observe = future_obs\n",
    "        new_observe[0] = future_time_features[0, 0]\n",
    "        new_observe[1:3] = future_time_features[0, 4:6]\n",
    "        distance = ((self.goal_long-long)**2 + (self.goal_lat-lat)**2 )**0.5\n",
    "        new_observe[3] = distance\n",
    "        new_observe[-4:] = fc, sog, lat, long\n",
    "        # new_observe[-4:] = future_obs[16:19]\n",
    "\n",
    "        # append new observations and actions\n",
    "        self.obs = np.append(self.obs, np.expand_dims(new_observe, 0), axis=0)\n",
    "        self.actions = np.append(self.actions, np.expand_dims(action, 0), axis=0)\n",
    "\n",
    "        return fc ,sog, lat, long\n",
    "\n",
    "    def _predict(self, past_values, past_time_features, future_time_features, tf_model, gru_model):\n",
    "        future_time_features = torch.from_numpy(np.expand_dims(future_time_features, 0)).float().to(self.device)\n",
    "        past_values = torch.from_numpy(np.expand_dims(past_values, 0)).float().to(self.device)\n",
    "        past_time_features = torch.from_numpy(np.expand_dims(past_time_features, 0)).float().to(self.device)\n",
    "        static_real_features = torch.from_numpy(np.expand_dims(self.statics, 0)).float().to(self.device)\n",
    "        past_observed_mask = torch.ones(past_values.shape).to(self.device)\n",
    "\n",
    "        # print(past_values.shape, past_time_features.shape, future_time_features.shape)\n",
    "        # make prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = tf_model.generate(past_values=past_values, past_time_features=past_time_features,\n",
    "                    static_real_features=static_real_features, past_observed_mask=past_observed_mask,\n",
    "                    future_time_features=future_time_features).sequences.mean(dim=1)\n",
    "            outputs = gru_model(outputs, past_time_features).detach().cpu().numpy()\n",
    "        return outputs[0,0,0], outputs[0,0,1]\n",
    "\n",
    "    def _get_reward(self, long, lat, fc):\n",
    "        # reward 1 distance to the top 1\n",
    "        reward1 = - ((long-self.top1.loc[self.current_step, \"LONGITUDE\"])**2 + (lat-self.top1.loc[self.current_step, \"LATITUDE\"])**2 )**0.5\n",
    "        if reward1 > -0.05:\n",
    "            reward1 = 0\n",
    "        # reward 2 fc and done reward\n",
    "        reward2 = -fc\n",
    "        # reward 3 mimic reward\n",
    "        if self.current_step < len(self.data):\n",
    "            reward3 = - ((long-self.data[self.current_step, 19])**2 + (lat-self.data[self.current_step, 18])**2 )**0.5\n",
    "        else:\n",
    "            reward3 = - ((long-self.data[-1, 19])**2 + (lat-self.data[-1, 18])**2 )**0.5\n",
    "        # reward 4 timeout reward\n",
    "        reward4 = 0\n",
    "        if self.current_step >= 100:\n",
    "            reward4 = -0.1*((self.current_step-90)//10)\n",
    "        return (reward1 + reward2 + reward3 + reward4) / 4\n",
    "\n",
    "    def step(self, action, test=False):\n",
    "        obs= self._get_observation()\n",
    "        self.current_step += 1\n",
    "\n",
    "        fc, sog, lat, long = self._take_action(action)\n",
    "        if test:\n",
    "            return fc, sog, lat, long\n",
    "\n",
    "        # get done and termination\n",
    "        done = (((long-self.goal_long)**2 + (lat-self.goal_lat)**2) < 1e-2)\n",
    "        termination =  self.current_step >= 124\n",
    "\n",
    "        reward = self._get_reward(long, lat, fc)\n",
    "        self.reward_cum = self.reward_cum + reward\n",
    "\n",
    "        if done:\n",
    "            reward = reward+1\n",
    "        return obs, reward, done, termination, {}\n",
    "\n",
    "\n",
    "    def _inv_transform_location(self, lat, long):\n",
    "        array = np.zeros([1, 12],dtype=np.float64)\n",
    "        array[0, [7,8]] = lat, long\n",
    "        lat, long = self.scaler.inverse_transform(array)[0,[7, 8]]\n",
    "        return lat, long\n",
    "\n",
    "    def _transform_value(self, vals, indexes):\n",
    "        array = np.zeros([1, 12],dtype=np.float64)\n",
    "        for i in range(len(indexes)):\n",
    "            array[0, indexes[i]] = vals[i]\n",
    "        transformed_val = self.scaler.transform(array)[0, [indexes]]\n",
    "        return transformed_val[0]\n",
    "\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        lat, long = self.obs[:, -2].copy(), self.obs[:, -1].copy()\n",
    "        for i in range(len(lat)):\n",
    "            lat[i], long[i] = self._inv_transform_location(lat[i], long[i])\n",
    "\n",
    "        # root = Tk()\n",
    "\n",
    "        # root.geometry('750x400')\n",
    "        # button1=Button(text='button1',bg='blue',fg='yellow',bd=2,anchor=SW,activebackground='pink',activeforeground='white',height=2,width=8,underline=0,font=('华文行楷',20),padx=20,pady=30,state=ACTIVE,wraplength=120,justify=RIGHT,cursor='cross')\n",
    "        # button1.grid(row=4,column=7)\n",
    "\n",
    "        # button2=Button(root,text='button2',bg='purple',font=('华文行楷',20),fg='blue',width=8,height=5,anchor=E,padx=20)\n",
    "        # button2.grid(row=4,column=1)\n",
    "\n",
    "        # button4=Button(root,bitmap='question',bd=2)\n",
    "        # button4.grid(row=1,column=5)\n",
    "\n",
    "        # button5=Button(root,relief=SUNKEN,text='button3')\n",
    "        # button5.grid(row=1,column=4)\n",
    "\n",
    "        # root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VesselEnvironment(rl_data)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform_cols = [ 'current', 'rain', 'snowfall', \"pressure\", 'wind_force', \"resist_ratio\",\n",
    "#        'FC', \"LATITUDE\", 'LONGITUDE', 'SOG', \"DEPTH\", \"SPEED\"]\n",
    "fcs = []\n",
    "sogs = []\n",
    "longs = []\n",
    "lats = []\n",
    "for i in range(6):\n",
    "    array = np.zeros((len(rl_data[i][\"observations\"]), 12))\n",
    "    array[:, 6] = rl_data[i][\"observations\"][:, -4]\n",
    "    array[:, 9] = rl_data[i][\"observations\"][:, -3]\n",
    "    array[:, 7] = rl_data[i][\"observations\"][:, -2]\n",
    "    array[:, 8] = rl_data[i][\"observations\"][:, -1]\n",
    "    # array = minmax_scaler.inverse_transform(array)\n",
    "    fcs.append(array[:, 6])\n",
    "    sogs.append(array[:, 9])\n",
    "    lats.append(array[:, 7])\n",
    "    longs.append(array[:, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VesselEnvironment(rl_data[:7], scaler=minmax_scaler)\n",
    "env.reset()\n",
    "fc_predicted = []\n",
    "sog_predicted = []\n",
    "lat_predicted = []\n",
    "long_predicted = []\n",
    "for i in range(1,7):\n",
    "    length = rl_data[i][\"observations\"].shape[0]\n",
    "    fc = np.zeros((length))\n",
    "    sog =  np.zeros((length))\n",
    "    lat = np.zeros((length))\n",
    "    long = np.zeros((length))\n",
    "    for j in range(25, length):\n",
    "        action = rl_data[i][\"actions\"][j]\n",
    "        # action[1] = action[1]\n",
    "        res = env.step(action, test=True)\n",
    "    #     # print(res)\n",
    "        fc[j], sog[j], lat[j], long[j] = res[0], res[1], res[2], res[3]\n",
    "    array1 = np.zeros((length, 12))\n",
    "    array1[:, 6] = fc\n",
    "    array1[:, 9] = sog\n",
    "    array1[:, 7] = lat\n",
    "    array1[:, 8] = long\n",
    "    # array1 = minmax_scaler.inverse_transform(array1)\n",
    "    fc_predicted.append(array1[:, 6])\n",
    "    sog_predicted.append(array1[:, 9])\n",
    "    lat_predicted.append(array1[:, 7])\n",
    "    long_predicted.append(array1[:, 8])\n",
    "    if(i<6):\n",
    "        env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(6):\n",
    "#     length = len(fc_predicted[i])\n",
    "#     array = np.zeros((length, 10))\n",
    "#     array[:, 5] = fc_predicted[i]\n",
    "#     array[:, 6] = lat_predicted[i]\n",
    "#     array[:, 7] = long_predicted[i]\n",
    "#     array = minmax_scaler.inverse_transform(array)\n",
    "#     fc_predicted[i] = (array[:, 5])\n",
    "#     lat_predicted[i] = (array[:, 6])\n",
    "#     long_predicted[i] = (array[:, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics import mean_squared_error\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "\n",
    "i=4\n",
    "def plot(i):\n",
    "    fig = plt.figure()\n",
    "    grid = plt.GridSpec(2, 2, wspace=0.3, hspace=0.3)\n",
    "\n",
    "    ax1 = plt.subplot(grid[0, 0])\n",
    "    ax2 = plt.subplot(grid[0, 1:])\n",
    "    ax3 = plt.subplot(grid[1, :1])\n",
    "    ax4 = plt.subplot(grid[1, 1:])\n",
    "    mse1 = mean_squared_error(fc_predicted[i][25:], fcs[i+1][25:], squared=False)\n",
    "    mse2 = mean_squared_error(long_predicted[i][25:], longs[i+1][25:], squared=False)\n",
    "    mse3 = mean_squared_error(lat_predicted[i][25:], lats[i+1][25:], squared=False)\n",
    "    mse4 = mean_squared_error(sog_predicted[i][25:], sogs[i+1][25:], squared=False)\n",
    "\n",
    "    ax1.plot(range(25, len(fc_predicted[i])), fc_predicted[i][25:], label='predictions'.format(i=2))\n",
    "    ax1.plot(range(25, len(fc_predicted[i])), fcs[i+1][25:], label='actuals'.format(i=1))\n",
    "    ax1.legend(loc='best')\n",
    "    ax1.set_title(\"fc, rmse: {}\".format(mse1))\n",
    "    ax2.plot(range(25, len(fc_predicted[i])), long_predicted[i][25:], label='predictions'.format(i=2))\n",
    "    ax2.plot(range(25, len(fc_predicted[i])), longs[i+1][25:], label='actuals'.format(i=1))\n",
    "    ax2.legend(loc='best')\n",
    "    ax2.set_title(\"longitude, rmse: {}\".format(mse2))\n",
    "    ax3.plot(range(25, len(fc_predicted[i])), lat_predicted[i][25:], label='predictions'.format(i=2))\n",
    "    ax3.plot(range(25, len(fc_predicted[i])), lats[i+1][25:], label='actuals'.format(i=1))\n",
    "    ax3.legend(loc='best')\n",
    "    ax3.set_title(\"latitude, rmse: {}\".format(mse3))\n",
    "    ax4.plot(range(25, len(sog_predicted[i])), sog_predicted[i][25:], label='predictions'.format(i=2))\n",
    "    ax4.plot(range(25, len(sog_predicted[i])), sogs[i+1][25:], label='actuals'.format(i=1))\n",
    "    ax4.legend(loc='best')\n",
    "    ax4.set_title(\"sog, rmse: {}\".format(mse4))\n",
    "\n",
    "    # plt.savefig(\"env_test_trip{}.jpg\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
