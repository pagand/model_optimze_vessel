{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../train.csv\")\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # H-N\n",
    "# d1 = df[df.direction==1][[\"LONGITUDE\", \"LATITUDE\",\"FC\", \"trip_id\"]] # h-n\n",
    "# d2 = df[df.direction==0][[\"LONGITUDE\", \"LATITUDE\",\"FC\", \"trip_id\"]] # n-h\n",
    "\n",
    "# # get the avg location of the top 1 percent trip\n",
    "# def get_top1_location(d1):\n",
    "#     total = d1.trip_id.nunique() // 100\n",
    "#     top_1_trips = list(d1.groupby(\"trip_id\").FC.sum().sort_values()[:total].index)\n",
    "#     i = top_1_trips.pop(0)\n",
    "#     hn_top = d1[d1.trip_id==i].reset_index(drop=True)\n",
    "#     if (len(hn_top) < 200):\n",
    "#         for j in range(200-len(hn_top)):\n",
    "#             hn_top = hn_top.append(hn_top.tail(1)).reset_index(drop=True)\n",
    "#     for i in top_1_trips:\n",
    "#         tmp_df2 = df[df.trip_id==i].reset_index(drop=True)\n",
    "#         if (len(tmp_df2) < 200):\n",
    "#             for j in range(200-len(tmp_df2)):\n",
    "#                 tmp_df2 = tmp_df2.append(tmp_df2.tail(1)).reset_index(drop=True)\n",
    "#         hn_top[\"LONGITUDE\"] = hn_top.LONGITUDE + tmp_df2.LONGITUDE\n",
    "#         hn_top[\"LATITUDE\"] = hn_top.LATITUDE + tmp_df2.LATITUDE\n",
    "#     hn_top[\"LONGITUDE\"] = hn_top[\"LONGITUDE\"]/(len(top_1_trips)+1)\n",
    "#     hn_top[\"LATITUDE\"] = hn_top[\"LATITUDE\"]/(len(top_1_trips)+1)\n",
    "#     return hn_top[[\"LONGITUDE\", \"LATITUDE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hn_top = get_top1_location(d1)\n",
    "# nh_top = get_top1_location(d2)\n",
    "\n",
    "# hn_top.to_csv(\"H2N_top1.csv\", index=False)\n",
    "# nh_top.to_csv(\"N2H_top1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn_top = pd.read_csv(\"../data/H2N_top1.csv\")\n",
    "nh_top = pd.read_csv(\"../data/N2H_top1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hn_top_np = np.zeros((len(hn_top), 18))\n",
    "# hn_top_np[:,13] = hn_top[\"LATITUDE\"]\n",
    "# hn_top_np[:,14] = hn_top[\"LONGITUDE\"]\n",
    "# hn_top_np = minmax_scaler.transform(hn_top_np)\n",
    "# hn_top[\"LATITUDE\"] = hn_top_np[:,13]\n",
    "# hn_top[\"LONGITUDE\"] = hn_top_np[:,14]\n",
    "\n",
    "# nh_top_np = np.zeros((len(nh_top), 18))\n",
    "# nh_top_np[:,13] = nh_top[\"LATITUDE\"]\n",
    "# nh_top_np[:,14] = nh_top[\"LONGITUDE\"]\n",
    "# nh_top_np = minmax_scaler.transform(nh_top_np)\n",
    "# nh_top[\"LATITUDE\"] = nh_top_np[:,13]\n",
    "# nh_top[\"LONGITUDE\"] = nh_top_np[:,14]\n",
    "# nh_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observations(df, feature_cols = [\"Time2\", \"turn\", \"acceleration\",\n",
    "       \"distance\", 'current', 'rain', 'snowfall', 'wind_force', 'wind_direc', \"resist_ratio\",\n",
    "       'change_x_factor', 'change_y_factor', \n",
    "       \"is_weekday\", 'direction', \"season\", \"hour\", \n",
    "       \"FC\", \"SOG\", \"LATITUDE\", 'LONGITUDE',\n",
    "       ], \n",
    "       action_cols = [\"SPEED\", \"HEADING\", \"MODE\"]):\n",
    "    # df = df.fillna(0)\n",
    "    \n",
    "    features = df.copy()\n",
    "\n",
    "    rewards_col = [\"trip_id\", \"LONGITUDE\", \"LATITUDE\", \"direction\", \"goal_long\", \"goal_lat\"]\n",
    "    rewards_df = features[rewards_col]\n",
    "    # apply minmax scaler for fuel consumption to get reward 2\n",
    "    rewards_df[\"reward2\"] = - features[[\"FC\"]]\n",
    "\n",
    "    dataset_list = []\n",
    "    for i in list(df.trip_id.unique()):\n",
    "        data_dict = {}\n",
    "        # observations\n",
    "        observation = features[features.trip_id==i].drop(\"trip_id\", axis=1)[feature_cols]\n",
    "        observation = observation.to_numpy().astype(float)\n",
    "        data_dict[\"observations\"] = observation\n",
    "\n",
    "        # next_observations\n",
    "        observation = np.delete(observation, 0, 0)\n",
    "        last = observation[-1]\n",
    "        observation = np.vstack([observation, last])\n",
    "        data_dict[\"next_observations\"] = observation\n",
    "\n",
    "        # actions \n",
    "        # print(i)\n",
    "        actions = features[features.trip_id==i].drop(\"trip_id\", axis=1)[action_cols]\n",
    "        # actions = actions.drop(\"trip_id\", axis=1)\n",
    "        data_dict[\"actions\"] = actions.to_numpy().astype(float)\n",
    "\n",
    "        # rewards\n",
    "        rewards = rewards_df[rewards_df.trip_id==i].reset_index()\n",
    "        rewards\n",
    "        # reward1 distance to top 1\n",
    "        trip_len = rewards.shape[0]\n",
    "        if rewards.loc[0,\"direction\"]==1:\n",
    "            top1 = hn_top.iloc[:trip_len]\n",
    "        else:\n",
    "            top1 = nh_top.iloc[:trip_len]\n",
    "        rewards[\"reward1\"] = - ((rewards[\"LONGITUDE\"]-top1[\"LONGITUDE\"])**2 + \\\n",
    "                             (rewards[\"LATITUDE\"]-top1[\"LATITUDE\"])**2 )**0.5\n",
    "        rewards[\"reward1\"].apply(lambda x: 0 if x > -0.05 else x)\n",
    "        rewards[\"reward1\"] = rewards[\"reward1\"]\n",
    "        # reward2 fc consumption an ddone reward\n",
    "        rewards.loc[len(rewards)-1,\"reward2\"] = rewards.loc[len(rewards)-1,\"reward2\"]+3\n",
    "        # rewards4 time out reward\n",
    "        rewards[\"Time\"] = rewards.index\n",
    "        rewards.reset_index(inplace=True)\n",
    "        rewards[\"reward3\"] = rewards[\"Time\"].apply(lambda x: -0.1*((x-90)//10) if x > 100 else 0)\n",
    "\n",
    "        data_dict[\"rewards\"] = (rewards[[\"reward1\",\"reward2\", \"reward3\"]]).to_numpy()\n",
    "\n",
    "        # termination\n",
    "        termination = np.zeros([observation.shape[0],1])\n",
    "        termination[-1,0] = 1\n",
    "        data_dict[\"termination\"] = termination\n",
    "\n",
    "        dataset_list.append(data_dict)\n",
    "    return dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yim/.local/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "rl_data = get_observations(df)\n",
    "with open('../data/rl_data.pkl', 'wb') as handle:\n",
    "    pickle.dump(rl_data,handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
