{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":85128,"status":"ok","timestamp":1694802542142,"user":{"displayName":"yimeng fan","userId":"16985736781704330809"},"user_tz":420},"id":"xrFY5FmCvzNO","outputId":"ca0be745-adc7-4e1b-dbd9-b852a6f048fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers==4.30.0\n","  Downloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.30.0)\n","  Downloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.0)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.30.0)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.17.1 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.30.0\n","Mounted at /content/drive\n"]}],"source":["!pip install -U transformers==4.30.0\n","\n","import math\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, PowerTransformer\n","import torch\n","import torch.nn as nn\n","from torch import nn, Tensor\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","from torch.autograd import Variable\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","import random\n","from sklearn.metrics import r2_score, mean_squared_error\n","from torch.optim.lr_scheduler import StepLR\n","from transformers import InformerForPrediction, InformerConfig\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5855,"status":"ok","timestamp":1694802547985,"user":{"displayName":"yimeng fan","userId":"16985736781704330809"},"user_tz":420},"id":"R04GvWUzv3dS"},"outputs":[],"source":["path = \"drive/MyDrive/feature1.csv\"\n","df = pd.read_csv(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ajcvulRUcz7H"},"outputs":[],"source":["class vessel_data(Dataset):\n","    def __init__(self, train = True, test=False, train_test_split = 0.7, rand_seed=1):\n","        ##########################inputs##################################\n","        #data_dir(string) - directory of the data#########################\n","        #size(int) - size of the images you want to use###################\n","        #train(boolean) - train data or test data#########################\n","        #train_test_split(float) - the portion of the data for training###\n","        #augment_data(boolean) - use data augmentation or not#############\n","        super(vessel_data, self).__init__()\n","        # todo\n","        #initialize the data class\n","        trips = list(df.trip_id.unique())\n","        self.train = train\n","        self.sequence_length = sequence_length\n","        self.prediction_horizon = prediction_horizon\n","\n","        # train_test_split\n","        random.seed(rand_seed)\n","        train_size = int(np.ceil(len(trips)*train_test_split))\n","        train_trips = random.sample(trips, k=train_size)\n","        if train:\n","            self.trips_id = train_trips\n","            # self.trips_id = train_trips[0:2]\n","        else:\n","            test_trips = [ x for x in trips if x not in train_trips]\n","            valid_trips = random.sample(test_trips, k = int(np.ceil(len(trips)*((1-train_test_split)*.7))))\n","            if test==False:\n","                self.trips_id = valid_trips\n","            else:\n","                self.trips_id = [ x for x in test_trips if x not in valid_trips]\n","        # self.starting_dict = self.get_starting(df)\n","\n","    # convert a df to tensor\n","    def df_to_tensor(self, df):\n","        numpy = df.to_numpy(dtype=\"double\")\n","        if torch.cuda.is_available():\n","            device = torch.device('cuda:0')\n","        else:\n","            device = torch.device('cpu')\n","        # return torch.from_numpy(df.values.astype(\"float\")).float().to(device)\n","        return torch.from_numpy(numpy).float().to(device)\n","\n","\n","    def __getitem__(self, idx):\n","        #load corresponding trip id from index idx of your data\n","        trip_id = (self.trips_id[idx//2])\n","        # start = self.starting_dict[trip_id]\n","        # start_idx = self.starting_dict[trip_id] + (idx%3)*(self.prediction_horizon+self.sequence_length)\n","        data = df[df.trip_id==trip_id].reset_index(drop=True)\n","        shifted_data = shifted_df[df.trip_id==trip_id].reset_index(drop=True)\n","        starting = 0\n","        if (idx%2):\n","            starting = len(data)-91\n","\n","        starting = 0\n","        data = data.iloc[starting:starting+91]\n","\n","        values = data[y_cols]\n","        time_features = data[time_feature + dynamic_real_feature]\n","        static_categorical_features = data.iloc[0][static_categorical_feature]\n","        future_time_features = shifted_data.iloc[starting:starting+91][time_feature + dynamic_real_feature]\n","        actions = data[[\"SPEED\", \"HEADING\", \"MODE\", \"turn\"]]\n","        return self.df_to_tensor(values), self.df_to_tensor(time_features), self.df_to_tensor(static_categorical_features), self.df_to_tensor(future_time_features), self.df_to_tensor(actions)\n","\n","    def __len__(self):\n","        return len(self.trips_id)*2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1867,"status":"ok","timestamp":1694729326094,"user":{"displayName":"yimeng fan","userId":"16985736781704330809"},"user_tz":420},"id":"zPyZ1V4dis9f","outputId":"618e2d73-362b-4e4a-ce93-9c7419816111"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at huggingface/informer-tourism-monthly were not used when initializing InformerForPrediction: ['model.embedder.embedders.0.weight']\n","- This IS expected if you are initializing InformerForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing InformerForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of InformerForPrediction were not initialized from the model checkpoint at huggingface/informer-tourism-monthly and are newly initialized because the shapes did not match:\n","- model.encoder.embed_positions.weight: found shape torch.Size([48, 32]) in the checkpoint and torch.Size([29, 32]) in the model instantiated\n","- model.decoder.embed_positions.weight: found shape torch.Size([48, 32]) in the checkpoint and torch.Size([29, 32]) in the model instantiated\n","- parameter_projection.proj.0.weight: found shape torch.Size([1, 32]) in the checkpoint and torch.Size([2, 32]) in the model instantiated\n","- parameter_projection.proj.0.bias: found shape torch.Size([1]) in the checkpoint and torch.Size([2]) in the model instantiated\n","- parameter_projection.proj.1.weight: found shape torch.Size([1, 32]) in the checkpoint and torch.Size([2, 32]) in the model instantiated\n","- parameter_projection.proj.1.bias: found shape torch.Size([1]) in the checkpoint and torch.Size([2]) in the model instantiated\n","- parameter_projection.proj.2.weight: found shape torch.Size([1, 32]) in the checkpoint and torch.Size([2, 32]) in the model instantiated\n","- parameter_projection.proj.2.bias: found shape torch.Size([1]) in the checkpoint and torch.Size([2]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["if torch.cuda.is_available():\n","    device = torch.device('cuda:0')\n","else:\n","    device = torch.device('cpu')\n","# device = torch.device('cpu')\n","\n","batch_size=256\n","sequence_length = 25\n","context_length = 24\n","prediction_horizon = 5\n","# criterion = Weighted_Loss()\n","\n","time_feature = [\"Time2\"]\n","dynamic_real_feature = [ \"SPEED\", \"HEADING\", \"MODE\", \"turn\", \"acceleration\",\n","       'current', 'rain', 'snowfall', 'wind_force', 'wind_direc', \"resist_ratio\"]\n","static_categorical_feature = [\"is_weekday\", 'direction',\"season\", \"hour\"]\n","y_cols = [\"FC2\", \"SOG2\"]\n","\n","config = InformerConfig.from_pretrained(\"huggingface/informer-tourism-monthly\", prediction_length=prediction_horizon,\n","        context_length=context_length, input_size=len(y_cols), num_time_features=len(time_feature),\n","        num_dynamic_real_features = len(dynamic_real_feature), num_static_real_features = len(static_categorical_feature),\n","        lags_sequence=[1], num_static_categorical_features=0, feature_size=22)\n","model = InformerForPrediction.from_pretrained(\"huggingface/informer-tourism-monthly\",\n","                                                           config=config, ignore_mismatched_sizes=True).to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2pkAXkKFmYra"},"outputs":[],"source":["class GRU_update(nn.Module):\n","    def __init__(self, input_size, hidden_size=1, output_size=4, num_layers=1, prediction_horizon=5):\n","        super().__init__()\n","        self.h = prediction_horizon\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n","        self.mlp = nn.Sequential( nn.ReLU(),\n","                                  nn.Linear(hidden_size, 2048),\n","                                  nn.Dropout(0.2),\n","                                  nn.ReLU(),\n","                                  nn.Linear(2048, output_size))\n","        self.hx_fc = nn.Linear(2*hidden_size, hidden_size)\n","\n","    def forward(self, predicted_values, past_time_features):\n","        xy = torch.zeros(size=(past_time_features.shape[0], 1, self.output_size)).float().to(device)\n","        hx = past_time_features.reshape(-1, 1, self.hidden_size)\n","        hx = hx.permute(1, 0, 2)\n","        out_wp = list()\n","        for i in range(self.h):\n","            ins = torch.cat([xy, predicted_values[:, i:i+1, :]], dim=1) # x\n","            hx, _ = self.gru(ins, hx.contiguous())\n","            hx = hx.reshape(-1, 2*self.hidden_size)\n","            hx = self.hx_fc(hx)\n","            d_xy = self.mlp(hx).reshape(-1, 1, self.output_size) #control v4\n","            hx = hx.reshape(1, -1, self.hidden_size)\n","            # print(\"dxy\", d_xy)\n","            xy = xy + d_xy\n","            # print(\"xy plused\", xy)\n","            out_wp.append(xy)\n","        pred_wp = torch.stack(out_wp, dim=1).squeeze(2)\n","        return pred_wp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jNCkYi-_ZQju"},"outputs":[],"source":["trainset = vessel_data(train = True, train_test_split = 0.8, rand_seed=1)\n","trainloader = DataLoader(trainset, batch_size = batch_size, shuffle=True, drop_last=True)\n","\n","validset = vessel_data(train = False, train_test_split = 0.8, rand_seed=1)\n","validloader = DataLoader(validset, batch_size = batch_size, drop_last=True)\n","\n","testset = vessel_data(train = False, test=True, train_test_split = 0.8, rand_seed=1)\n","testloader = DataLoader(testset, batch_size = batch_size, drop_last=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"grOPrQVMEOgj"},"outputs":[],"source":["model = model.float()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0IDENhuivt_h"},"outputs":[],"source":["gru = GRU_update(2, hidden_size=300, output_size=2, num_layers=1, prediction_horizon=5).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xbRR6X4zHL9a"},"outputs":[],"source":["#  train the model\n","def train_model(trainloader, testloader, model, model_name = \"transformer\"):\n","    for epoch in range(n_epochs):\n","        epoch_loss = 0\n","        mses = []\n","        r2s = []\n","        losses = []\n","        gru.train()\n","        model.train()\n","        for _, data in enumerate(trainloader):\n","            values, time_features, static_real_features, future_features, actions  = data\n","            for t in range(sequence_length, values.shape[1]-prediction_horizon):\n","                # for i in range(prediction_horizon):\n","                # if t!=25:\n","                #     values[:, t-1, :] =  predicted[:, 0, :]\n","                #     acceleration = predicted[:,0,1]- values[:, t-2, 1]\n","                #     time_features[:, t-1, 6] = acceleration\n","                # future_time_features = time_features[:, t-prediction_horizon:t]\n","                # future_time_features[:, 0, 1:5] = time_features[:, t, 1:5]  # from speed to turn\n","                # future_time_features[:, :, 0] = future_time_features[:, :, 0]+prediction_horizon\n","                # future_time_features[:, 0, 1:5] = actions[:, t, 0:4]\n","                # # future_values[:, :, 0] = values[:, t+i:t+prediction_horizon+i, 0]\n","                # future_values = values[:, t:t+prediction_horizon]\n","                # past_values = values[:, t-sequence_length: t]\n","                # past_time_features = time_features[:, t-sequence_length: t]\n","\n","                i = (t-sequence_length)%prediction_horizon\n","                # print(i)\n","                if i==0:\n","                    values_tmp = torch.clone(values[:, t-sequence_length:t+prediction_horizon*2])\n","                    time_features_tmp = torch.clone(time_features[:, t-sequence_length:t+prediction_horizon*2])\n","                    # print(values_tmp.shape, time_features_tmp.shape)\n","                else:\n","                    predicted = predicted.detach()\n","                    values_tmp[:, sequence_length-1 + i, :] =  predicted[:, 0, :]\n","                    acceleration = predicted[:, 0, 1]- values_tmp[:, sequence_length-2 + i, 1]\n","                    time_features_tmp[:, sequence_length-1 + i, 5] = acceleration\n","                future_time_features = time_features_tmp[:, sequence_length+i-prediction_horizon: sequence_length+i]\n","                future_time_features[:, 0, 1:5] = time_features_tmp[:, sequence_length + i, 1:5]  # from speed to turn\n","                future_time_features[:, :, 0] = future_time_features[:, :, 0]+prediction_horizon/120\n","\n","                future_values = values_tmp[:, sequence_length+i : sequence_length+i+prediction_horizon]\n","                past_values = values_tmp[:, i: sequence_length+i]\n","                past_time_features = time_features_tmp[:, i: sequence_length+i]\n","\n","                # print(past_values.shape, past_time_features.shape)\n","                # print(future_values.shape, future_time_features.shape)\n","\n","                # print(past_values.shape, past_time_features.shape)\n","                past_observed_mask = torch.ones(past_values.shape).to(device)\n","                optimizer1.zero_grad()\n","                optimizer2.zero_grad()\n","                tf_out = model(past_values=past_values, past_time_features=past_time_features, static_real_features=static_real_features,\n","                            past_observed_mask=past_observed_mask, future_values=future_values, future_time_features=future_time_features, output_hidden_states=True)\n","                loss1 = tf_out.loss\n","                loss1.backward()\n","                with torch.no_grad():\n","                    predicted_tf = model.generate(past_values=past_values, past_time_features=past_time_features, static_real_features=static_real_features,\n","                                  past_observed_mask=past_observed_mask, future_time_features=future_time_features).sequences.mean(dim=1)\n","                predicted = gru(predicted_values = predicted_tf, past_time_features=past_time_features)\n","\n","                loss2 = criterion(predicted, future_values)\n","\n","                # loss = prediction.loss\n","                epoch_loss += loss2.item()\n","                loss2.backward()\n","                optimizer1.step()\n","                optimizer2.step()\n","                # predicted = model.generate(past_values=past_values, past_time_features=past_time_features, static_real_features=static_real_features,\n","                            # past_observed_mask=past_observed_mask, future_time_features=future_time_features).sequences.mean(dim=1)\n","        # scheduler.step()\n","        epoch_loss = epoch_loss / len(trainloader) / (91-25)\n","        print('Epoch %d / %d --- Loss: %.8f' % (epoch, n_epochs, epoch_loss))\n","        # mse, r2 = evaluate_model(testloader, model)\n","        mse, r2 = evaluate_model(testloader, model)\n","        print('valid MSES: {}'.format(mse))\n","        print('valid R2s:  {}'.format(r2))\n","\n","        mses.append(mse)\n","        r2s.append(r2)\n","        losses.append(epoch_loss)\n","        path = \"drive/MyDrive/{}_checkpoint{}.pt\".format(model_name, epoch)\n","        torch.save(model.state_dict(), path)\n","        path = \"drive/MyDrive/{}_checkpoint{}_gru.pt\".format(model_name, epoch)\n","        torch.save(gru.state_dict(), path)\n","    # path = \"drive/MyDrive/{}_final.pt\".format(model_name, n_epochs)\n","    # torch.save(model.state_dict(), path)\n","    return mses, r2s, losses"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EElTV6wo7CJO"},"outputs":[],"source":["def evaluate_model(testloader, model, mode=\"valid\", i=0):\n","    gru.eval()\n","    model.eval()\n","    predictions = []\n","    actuals = []\n","    mses = [[] for _ in range(2)]\n","    r2s =[[] for _ in range(2)]\n","    with torch.no_grad():\n","      for _, data in enumerate(testloader):\n","            outputs = None\n","            act = []\n","            pred = []\n","            values, time_features, static_real_features, future_features, actions  = data\n","            values_tmp = torch.clone(values)\n","            for t in range(sequence_length, values.shape[1]-prediction_horizon):\n","                future_values = values[:, t : t+prediction_horizon]\n","                if outputs != None:\n","                    predicted = outputs.detach()\n","                    values_tmp[:, t-1, :] =  predicted[:, 0, :]\n","                    acceleration = predicted[:, 0, 1]- values_tmp[:, t-2, 1]\n","                    time_features[:, t-1, 5] = acceleration\n","\n","                future_time_features = time_features[:, t-prediction_horizon: t]\n","                future_time_features[:, 0, 1:5] = time_features[:, t, 1:5]  # from speed to turn\n","                future_time_features[:, :, 0] = future_time_features[:, :, 0]+prediction_horizon/120\n","\n","                future_values = values[:, t : t+prediction_horizon]\n","                past_values = values_tmp[:, t-sequence_length: t]\n","                past_time_features = time_features[:, t-sequence_length: t]\n","\n","                past_observed_mask = torch.ones(past_values.shape).to(device)\n","                # return past_values, past_time_features, static_categorical_features, past_observed_mask, future_time_features\n","                # outputs = model.generate(past_values=past_values, past_time_features=past_time_features, static_real_features=static_real_features,\n","                                        # past_observed_mask=past_observed_mask, future_time_features=future_time_features).sequences.mean(dim=1)\n","                predicted_tf = model.generate(past_values=past_values, past_time_features=past_time_features, static_real_features=static_real_features,\n","                                        past_observed_mask=past_observed_mask, future_time_features=future_time_features).sequences.mean(dim=1)\n","                outputs = gru(predicted_tf, past_time_features)\n","                yhat = outputs[:, 0, :].detach().cpu().numpy()\n","                actual = values[:, t, :].detach().cpu().numpy()\n","\n","                # store\n","                act.append(actual)\n","                pred.append(yhat)\n","            act = np.stack(act, axis=1)\n","            pred = np.stack(pred, axis=1)\n","            for i in range(2):\n","                mse = mean_squared_error(act[:, i], pred[:, i])\n","                mses[i].append(mse)\n","                actual_1 = act[:, i].swapaxes(1, 0).reshape([-1, 1])\n","                yhat_1 = pred[:, i].swapaxes(1, 0).reshape([-1, 1])\n","                r2 = r2_score(actual_1, yhat_1)\n","                r2s[i].append(r2)\n","            predictions.append(pred)\n","            actuals.append(act)\n","    mses = [ sum(x)/len(x) for x in mses]\n","    r2s = [ sum(x)/len(x) for x in r2s]\n","\n","    if mode==\"test\":\n","      return mses, r2s, [actuals, predictions]\n","    # calculate mse\n","    return mses, r2s\n","    #actuals[:20], predictions[:20]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":202,"status":"ok","timestamp":1694730022497,"user":{"displayName":"yimeng fan","userId":"16985736781704330809"},"user_tz":420},"id":"ZSNbVN1QpR8f","outputId":"75791e41-4868-4ebd-965f-88d7df5360f7"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load(\"drive/MyDrive/gru_3_checkpoint8.pt\"))\n","gru.load_state_dict(torch.load(\"drive/MyDrive/gru_3_checkpoint8_gru.pt\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EDfqFZbNiJ9-"},"outputs":[],"source":["iter = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sACSW1PjD1q7"},"outputs":[],"source":["iter = iter+1\n","criterion = torch.nn.MSELoss()\n","print(iter)\n","n_epochs = 30\n","optimizer1 = torch.optim.Adam(model.parameters(), lr= 1e-5)\n","optimizer2 = torch.optim.Adam(gru.parameters(), lr= 1e-5)\n","\n","# scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n","mses, r2s, losses = train_model(trainloader, validloader, model, \"gru_{}\".format(iter))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kui_Q6xKMTKI"},"outputs":[],"source":["mses, r2s, [actuals, predictions ] = evaluate_model(testloader, model, mode=\"test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E4uD1be3rN6L"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNhwVNrcq/hgfLGb7gaJxc0","gpuType":"T4","provenance":[{"file_id":"1yYLUNv-tSo77MOXOCdN8ou9WqPLz4rrI","timestamp":1694802819564},{"file_id":"1tjVuN5vzMynVZbmnX6Iq6DWyiMSkG9ls","timestamp":1694389097800},{"file_id":"1x6Ot7q6thXCqTYSBoauVnJ7z5atxV_62","timestamp":1694302118867},{"file_id":"1C08m5CWZAG59AD6nfpiNVPWHqhRqVj1g","timestamp":1693328429337}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
